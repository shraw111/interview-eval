# ğŸš€ Full Stack Setup Guide

Complete setup instructions for the Interview Agent with Next.js frontend and FastAPI backend.

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js       â”‚  HTTP   â”‚   FastAPI        â”‚  Code   â”‚   LangGraph     â”‚
â”‚   Frontend      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Backend        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Evaluation    â”‚
â”‚   (Port 3000)   â”‚         â”‚   (Port 8000)    â”‚         â”‚   Engine        â”‚
â”‚                 â”‚         â”‚                  â”‚         â”‚                 â”‚
â”‚                 â”‚  WS     â”‚                  â”‚         â”‚   (Existing     â”‚
â”‚                 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   WebSocket      â”‚         â”‚    src/graph/)  â”‚
â”‚                 â”‚         â”‚   Real-time      â”‚         â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Prerequisites

- **Python 3.10+**
- **Node.js 18+** and npm
- **Azure OpenAI API credentials** (already configured in `.env`)

---

## ğŸ”§ Backend Setup (FastAPI)

### 1. Install Dependencies

```bash
cd backend
pip install fastapi uvicorn[standard] python-multipart pydantic-settings
```

The backend reuses all existing dependencies from your root `requirements.txt` (langchain, langgraph, openai, etc.)

### 2. Start the Backend Server

```bash
cd backend
python run.py
```

You should see:
```
ğŸš€ Interview Agent API started
ğŸ“š API docs: http://localhost:8000/docs
ğŸ”Œ WebSocket: ws://localhost:8000/ws/evaluations/{evaluation_id}
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### 3. Test Backend (Optional)

Visit http://localhost:8000/docs to see the interactive API documentation.

Test health check:
```bash
curl http://localhost:8000/api/v1/health
```

---

## ğŸ¨ Frontend Setup (Next.js)

### 1. Install Dependencies

Open a **NEW terminal** (keep backend running):

```bash
cd frontend
npm install
```

This will install all Next.js, React, Tailwind, shadcn/ui, and other frontend dependencies.

### 2. Start the Frontend Server

```bash
cd frontend
npm run dev
```

You should see:
```
  â–² Next.js 14.2.0
  - Local:        http://localhost:3000
  - Ready in 2.3s
```

---

## âœ¨ Using the Application

### 1. Open the App

Visit **http://localhost:3000** in your browser.

### 2. Fill Out the Evaluation Form

**Candidate Information:**
- Name: e.g., "Sarah Chen"
- Current Level: e.g., "L5 PM"
- Target Level: e.g., "L6 Senior PM"
- Years at Current Level: e.g., 3
- Level Expectations: Describe what distinguishes the target level

**Evaluation Rubric:**
Write your criteria in plain English:
```markdown
## Strategic Thinking
- Demonstrates long-term vision beyond immediate roadmap
- Makes decisions considering broader organizational impact

## Leadership & Influence
- Influences without authority across teams
- Builds consensus among stakeholders
```

**Interview Transcript:**
Either paste text directly or upload a .txt/.md file with the interview transcript.

### 3. Run the Evaluation

Click **"Run Evaluation"** button. You'll be redirected to the results page where you'll see:

- **Real-time progress bar** (0% â†’ 25% â†’ 50% â†’ 75% â†’ 100%)
- **4 agent status cards** updating live
- **WebSocket connection status**
- **Live token counts** as agents complete

### 4. View Results

Once complete (typically 2-3 minutes), you'll see:

- **Recommendation badge** (STRONG RECOMMEND / RECOMMEND / BORDERLINE / DO NOT RECOMMEND)
- **Metrics**: Execution time, total tokens, cost, model version
- **Evaluation Journey**: 4-panel accordion showing:
  1. Primary Evaluation
  2. Peer Challenges
  3. Calibrated Response
  4. Final Decision

---

## ğŸ—ï¸ Project Structure

```
Interview Agent/
â”œâ”€â”€ backend/                          # FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                   # FastAPI entry point
â”‚   â”‚   â”œâ”€â”€ models/                   # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ services/                 # Business logic
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/               # REST endpoints
â”‚   â”‚   â”‚   â””â”€â”€ websocket/            # WebSocket handlers
â”‚   â”‚   â””â”€â”€ utils/                    # Graph executor
â”‚   â”œâ”€â”€ run.py                        # Server runner
â”‚   â””â”€â”€ requirements.txt              # Backend dependencies
â”‚
â”œâ”€â”€ frontend/                         # Next.js Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/                      # Pages (App Router)
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx              # Home (evaluation form)
â”‚   â”‚   â”‚   â””â”€â”€ evaluations/[id]/     # Results page
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/                   # shadcn/ui components
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluation/           # Evaluation components
â”‚   â”‚   â”‚   â””â”€â”€ shared/               # Shared components
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ api/                  # API client
â”‚   â”‚   â”‚   â”œâ”€â”€ websocket/            # WebSocket hook
â”‚   â”‚   â”‚   â””â”€â”€ validation/           # Zod schemas
â”‚   â”‚   â””â”€â”€ types/                    # TypeScript types
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ src/                              # Existing LangGraph Code (REUSED!)
â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”œâ”€â”€ graph.py                  # LangGraph workflow
â”‚   â”‚   â”œâ”€â”€ nodes.py                  # 4-agent implementations
â”‚   â”‚   â””â”€â”€ state.py                  # State definitions
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â””â”€â”€ manager.py                # Prompt versioning
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ azure_client.py           # Azure OpenAI client
â”‚
â”œâ”€â”€ data/                             # Prompts and rubrics
â”œâ”€â”€ config.yaml                       # Model configuration
â”œâ”€â”€ .env                              # Azure OpenAI credentials
â””â”€â”€ requirements.txt                  # Python dependencies
```

---

## ğŸ” How It Works

1. **User submits form** â†’ POST /api/v1/evaluations
2. **Backend validates** â†’ Creates evaluation ID, starts background task
3. **Frontend redirects** â†’ /evaluations/{id} page
4. **WebSocket connects** â†’ ws://localhost:8000/ws/evaluations/{id}
5. **LangGraph executes** â†’ Your existing 4-agent workflow from `src/graph/graph.py`
6. **Real-time updates** â†’ Backend streams progress events via WebSocket
7. **Frontend updates** â†’ Progress bar, agent cards update live
8. **Evaluation completes** â†’ Full results displayed with beautiful UI

---

## ğŸ› ï¸ Troubleshooting

### Backend won't start

**Error**: `ModuleNotFoundError: No module named 'fastapi'`
**Solution**:
```bash
cd backend
pip install fastapi uvicorn[standard] python-multipart pydantic-settings
```

### Frontend won't start

**Error**: `Cannot find module 'next'`
**Solution**:
```bash
cd frontend
npm install
```

### WebSocket not connecting

**Check**:
1. Backend is running on port 8000
2. Frontend is configured to connect to `ws://localhost:8000`
3. No firewall blocking WebSocket connections

### Evaluation fails with Azure OpenAI error

**Check**:
1. `.env` file has correct `AZURE_OPENAI_API_KEY` and `AZURE_OPENAI_ENDPOINT`
2. API key is valid and has credits
3. Backend logs show the error details

---

## ğŸ“Š API Endpoints

### REST API

- `POST /api/v1/evaluations` - Create evaluation
- `GET /api/v1/evaluations/{id}` - Get evaluation status
- `GET /api/v1/evaluations` - List evaluations
- `GET /api/v1/health` - Health check

### WebSocket

- `ws://localhost:8000/ws/evaluations/{id}` - Real-time progress stream

Interactive API docs: http://localhost:8000/docs

---

## ğŸ¯ Next Steps

### Enhancements

1. **History Page**: View past evaluations
2. **Prompt Editor**: UI for managing prompt versions
3. **Authentication**: Add user login
4. **Database**: Replace in-memory storage with PostgreSQL/Redis
5. **Export Reports**: Download PDF evaluations

### Deployment

1. **Backend**: Deploy to AWS/GCP/Azure (containerize with Docker)
2. **Frontend**: Deploy to Vercel/Netlify (automatic with Next.js)
3. **Production Config**: Update CORS origins, add HTTPS

---

## ğŸ™Œ Summary

You now have a complete full-stack AI evaluation system:

âœ… **Backend**: FastAPI with WebSocket streaming
âœ… **Frontend**: Beautiful Next.js UI with shadcn/ui
âœ… **Real-time**: Live progress updates
âœ… **Existing Code**: Reuses your LangGraph evaluation engine
âœ… **Type-safe**: TypeScript + Pydantic throughout

**Run both servers and visit http://localhost:3000 to start evaluating!** ğŸš€
